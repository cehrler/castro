Relying on the raw output of the SNER might not be sufficient if we desire reliable counts of NE's. One of the major problems is that the same
NE can be manifested in a variety of phrases. In order to know how many times a certain NE appears in a document, we should be able to identify all the phrases that refer to this entity. This task is known as CRR, and as described previously is extremely difficult to solve.

Nevertheless, it is possible to approximate CRR by focusing on aliasing--- grouping linguistic variants of names. Our aim is to increase the reliability of the IR and the document similarity measures by not treating strings such as \lingform{Castro} , \lingform{Dr. Castro} and \lingform{Fidel Castro} as different terms. Our approach to aliasing relies on string similarity. We measure similarity between NEs that belong to the same class using string kernels, implemented in C++ for efficiency due to the large amount of data to be processed. This method allows for more flexibility then other methods such as edit distance. In a second stage we expand (or ``smooth'') vector representations of documents with the aliases of the NE's they contain. This allows more reliable similarity measurement of document similarity as well as indirect query expansion for NEs. 

String kernels are kernel methods which operate on the domain of strings over
a finite alphabet $\Sigma$ and are often applied in the fields of IR and bioinformatics. In this project, a
$p$-spectrum string kernel was applied, defined as
\[k_p(s,t) = \sum_{u \in \Sigma^p}{\phi_u^p(s)\phi_u^p(t)},\]
where $\phi_u^p(s)$ counts the number of occurrences of the substring $u$ of length $p$ in $s$. The
associated Hilbert space for this kernel is $\mathbb{R}^{|\Sigma^p|}$--- the space of all possible
strings over $\Sigma$ of length $p$. The $p$-spectrum string kernel can be efficiently implemented by using trie data-structures and $n$-gram models.

Operating on the characters level, this method allows to calculate a similarity matrix between each pair of named entities of the same type. 
The complete kernel matrix $\textbf{K}$ was computed for all three types of NEs, where $\textbf{K}_{i,j}$ is the similarity measure of the NEs $i$ and $j$. Since many of the entries in $\textbf{K}$ are near zero, fixed-value thresholding was applied after the kernel matrix computation, storing the resulting sparse matrices for further use.

Having calculated this similarity matrix, we can apply it to the matrices that contain the document vectors. As a result, if the similarity rate of a possible alias of a NE that appears in the document exceeds a certain threshold the value of this alias in the document vector becomes non-zero. This approach is exemplified in the following figure.


\begin{figure}[ht]
  \caption{Aliasing of document with string kernel similarity measure.
The matrix $\mathcal{S}$ is the kernel matrix of the three terms $\mathcal{T} = \lbrace
\text{\lingform{Fidel Castro}},\text{\lingform{Dr. Fidel Castro}}, \text{\lingform{Raul}}\rbrace$. The first and second term have a
very high similarity measure of $0.8$, while the third term has a very low similarity measure. Using
$\mathcal{S}$, a document vector $d=(1,0,0)^T$ can be expanded into an aliased form
$\bar q$, where $\bar q = \mathcal{S}q$.}
  \[
     \underbrace{\begin{pmatrix}
      1   & 0.8 & 0\\
      0.8 & 1   & 0\\
      0   & 0   & 1\\
     \end{pmatrix}}_{\mathcal{S}}
     \underbrace{\begin{pmatrix}
     1\\ 0\\0 
     \end{pmatrix}}_{d}
     =
     \underbrace{\begin{pmatrix}
     1\\ 0.8\\0 
     \end{pmatrix}}_{\bar d}
  \]
  \label{eq:example_string_sim}
\end{figure}

After each document was multiplied by the kernel similarity matrix, it has pseudo-counts for all the variants of its NE's in the whole collection. This can be interpreted as if all variants of the name appeared in the document. 

Having these expanded representations gives us the effect of aliasing for two later processing steps. First, name variants no longer effect similarity measurements. For example if previously document 1 would have only the NEs \lingform{Castro} and document 2 would have only the NEs \lingform{Dr. Castro} their similarity would be 0. After the aliasing, both documents contain both terms, and thus have maximal similarity. A similar effect is achieved when measuring query document similarity. We discuss both implications in the relevant sections.


