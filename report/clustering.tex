The aim of graph clustering is to divide the nodes of the graph into the separate regions in such a way that the number of edges connecting the nodes inside the same region is big and the number of edges connecting the edges from the different regions is low.

At first we tried to use the k-means clustering which is general vector clustering algorithm. In this case the vector representations of the documents are used. These are the same vectors as in the index representation of the documents. In this algorithm number of clusters must be determined in advance. 

In the first step cluster centroids are initialized as the random vectors. 
In the second step each vector is assigned to it's closest cluster centroid.
In the third step each cluster centroid is updated in such a way that the cluster centroid lies exactly in the center of all vectors assigned to this cluster centroid.
Second and third step are repeated as long as the positions of the centroids change.
 
This approach didn't work very well. The produced clusters were not the densily connected regions. It was probably caused by the fact, that the dimensionality of the vector space is very high and that the vectors representing the documents are very sparse.


We decided to use rather the clustering algorithm that is directly aiming the problem of graph clustering.
The Chinese Whisper algorithm works as follows:

In the initialization step each vector is assigned to it's own cluster.

At the beginning of each update round, the randomly ordered list containing all nodes is created. It means that in each update round the ordering in which we update the node's cluster assignment is different.

The nodes are then pulled out from the list one by one, for each node the cluster assignment is updated. Updating of the node's assignment to the cluster works as follows: The neighbours of the focused node are grouped together according to their assignment to the clusters. The weights of the edges connecting the focused node with the nodes contained in the distinct group are sumed up together. The focused node is then assigned to the cluster for which the sum was greatest. For the later use we denote this greatest sum as the cluster assignment sum.

After few iterations the stable clustering is achieved (there are no changes in the cluster assignments) or there are few nodes ar the borders of the clusters that periodically flip their cluster assignment.

This algorithm worked much better than k-means clustering. But the problem of the algorithm is that it always change the node's cluster assignment to the strongest cluster in his neighbourhood. But sometimes the node is not strongly connected to none of the clusters and we would rather not include it in any cluster.

To handle this problem we implemented a variation of this algorithm. 

In the standard version the focused node is always assigned to the cluster for which the sum of edges was greatest. 

In our modified implementation the cluster assignment sum needs to be greater than a precomputed threshold, otherwise the focused node doesn't change its cluster assignment. In the current implementation this threshold is set to the mean of the edge strength over whole graph multiplied by the constant which can be specified in the clustering settings menu.

Before the update rounds, which works exactly like the update rounds in the standard version with the exception of the thresholding feature discribed in previous paragraph, are started, the predefined number of initialization steps are done.

For the purpose of the initialization steps, all edges of the graph are sorted in the descending order according to their weights. In each initialization step, one each is pulled out from the list and the standard node cluster assignment procedure is then executed on the node, for which the cluster assignment sum is greater. It means that the cluster assignment sum doesn't need to exceed the precomputed threshold.

By this we want to start up the clustering process because it may be hard to exceed the precomputed threshold at any node when all the nodes have their own cluster. Selecting the nodes attached to the edges with great weight ensures that the cluster assignments done during these initialization steps are not relevant.

The modified Chinese Whisper algorithm is a recent feature and it wasn't properly evaluated yet. With the right setting of the parameter the resulting clusters looks better than the clusters achieved by the standard algorithm. In the feature we should experiment with the different parameter settings. We should also find out whether it's a good idea to base the mean of the edge weights as the basis for the threshold computation. It may be better to choose predefined constant. We should also evaluate the impact of the initialization steps, how important they are for the algorithm and whether there is a better way how to start up the clustering.

Bibliography:
Chinese Whispers - an Efficient Graph Clustering Algorithm
and its Application to Natural Language Processing Problems
                            Chris Biemann
                University of Leipzig, NLP Department
                         Augustusplatz 10/11
                      04109 Leipzig, Germany
              biem@informatik.uni-leipzig.de


