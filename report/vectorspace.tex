We use the Vector Space Model (VSM) as our framework for representation of documents and queries. The VSM is an established approach in IR as it enables straightforward modeling of document-query similarity in order to determine relevance of documents to the query. More crucially, it enables us to model inter-document similarity which underlies the idea of linking similar and related documents. Both similarity notions can be modeled as proximity of vectors in the multidimensional vector space. Furthermore, the VSM is a convenient representation for implementation of clustering algorithms, which provide another tool for arranging the graph nodes in an informative manner.  

The VSM is a model for representing arbitrary data as vectors in Euclidean space. In IR, this representation is used for both documents and queries. In the The value of each element of the vector corresponds to the importance of a term for the representation of the query or the document. In this basic formulation the model treats both documents and queries as "bags of words" ignoring any order or structure related information. The vectors are usually normalized in order to have the same length (e.g.\ unit length)--- Otherwise, the model would favor larger documents. 

The elegant algebraic formulation and interpretation of the VSM make this model attractive from for theoretical and practical perspectives.
Another advantage of the VSM is its flexibility as compared to more restricted models such as boolean models. In boolean models, documents that do not exactly match the query are rejected. However, in many real world scenarios, the situation is different: The relevance of the document for the user is often graded rather then binary. The VSM can model this relevance scale.


\subsubsection{Indexing}
\label{sec:indexing}
Representing the documents of our collection in vector space requires the construction of an index. Given a set of documents $\mathcal{D}$ together with a set of terms $\mathcal{T}$ the index is a matrix $D \in \mathbb{R}^{|\mathcal{D}|\times |\mathcal{T}|}$ where $D_{d,i}$ corresponds to the importance of term $i$ in document $d$. In each column, the weights for one distinct term over all the documents is stored.

Index matrices are often very sparse: In our implementation, they are represented as a sparse matrix (linked lists)--- In the data structures, only coordinates of the non-zero entries are stored, all of the document vectors being normalized in advance. This allows the compute cosine similarities for documents and queries to be computed without being normalized first.

Our model contains several index matrices. We created an index matrix for each NE type and a general index for the non-NE terms (all terms occurring in the documents). For the NE's indexes we used the output of the SNRE. For the non-NE terms (general vocabulary) we used all the vocabulary of the collection, without any filtering. Indexes are also constructed on-the-fly for queries, using the query terms.

\subsubsection{Term Weighting}
\label{sec:term_weighting}
There are several measures that can be used to express the importance of the index term for the document, perhaps the most widely used being TF and TF-IDF.

TF is the frequency of a term in a given document. Hence, TF scores grow linearly with the number of occurrences of a term in the document. The TF score of term $i$ in document $d$ is defined as:
\[\text{TF}_d(i) = \frac{n_d(i)}{\sum_{i' \in \mathcal{T}}{n_d(i')}}\]
where $n_d(i)$ denotes the number of occurrences of term $i$ in document $d$ and $\mathcal{T}$ denotes the set of all terms. 

TF-IDF is the product of term frequency and the logarithm of inverse document frequency. This measure is based on the observation that terms which occur more commonly in documents overall are less useful than terms which occur less commonly in documents overall. The TF-IDF score of term $i$ in document $d$ is is defined as
\[\text{TF-IDF}_d(i)= \text{TF}_d(i)\log{\left(\frac{|D|}{|\lbrace d' : t(i) \in d' \rbrace|}\right)}\]
The TF-IDF score of term $i$ is proportional to the logarithm of the inverse fraction of documents that contain term $i$; The smaller the logarithm, the lower the TF-IDF score. Thus, the TF-IDF score of terms which are contained in every document always equals $0$.

The difference between these two weighting schemes can have a considerable impact on the ranking of the query results as well as on the similarity measurements between the documents. Using only TF may result in an unjustified high similarity between a pair of documents due to appearances of non-discriminative terms that are frequent in every document. For instance, two completely unrelated documents can have relatively high similarity measure simply since they share NE's such as \lingform{Fidel Castro} and \lingform{Cuba} or non-NE's such functional words. TF-IDF accounts for this problem by assigning low weights for non-discriminative terms. A similar problem can happen with query-document similarity. With respect to this issue, it seems that TF/IDF is a more suitable vector representation for our similarity measurements. However, since it is possible to think of scenarios where the TF could be useful, we enable the user to switch between the two, setting TF/IDF as default. 

\subsubsection{Computing Similarity between Documents}\label{sec:computing_similarity_between_documents}

As mentioned previously, our representation of the documents is based on their similarity to each other according to some extracted data. The edges of the resulting graphs are constructed based on these similarities. The crucial and difficult question is, how do the similar and related documents look like. This question can have various answers depending on the set of documents and the interests of the historian. Our working hypothesis is that the similarity and relatedness between the documents that might be relevant for the interest of the historian can be expressed as the similarity of the named entities. 
The assumption is that NE's of the sort we extract are more relevant for historically motivated similarity then other information that can be extracted from the documents. As we represent documents in VSM as the vectors of named entities, we can directly apply standard vector space measures for expressing similarities between vectors. 

The first measure we use is the cosine similarity measure. 
\[\text{cosim}(d,d') = \sum_{k \in \mathcal{T}}\frac{d(k)d'(k)}{|d||d'|}\]
It expresses the cosine angle between the vectors $d$ and $d'$. The cosine measure is equal to $1$ for the parallel vectors and is equal to $0$ for perpendicular vectors. The smaller the angle between the vectors, the more similar they are.

We also used "Manhattan similarity measure". The Manhattan similarity between two vectors can be described using the Manhattan distance between the zero vector and the minimum value for each column out of the two vectors.

\[\text{manhattan}(d,d') = \sum_{k \in \mathcal{T}}min[d(k), d'(k)]\]

We briefly compared both similarity measures by comparing the similarity graphs constructed using those measures. Though at first glance the edges look differently, it seems that the main reason for that concerns the different scalability of the two measures. Adjusting the similarity threshold of one of the graphs can yield rather similar edges to the other graph.

In the current version we use cosine similarity measure by default. We do that because this measure is more widespread that the Manhattan distance, and because of its elegant mathematical interpretation.

We computed similarity matrices in order to store the similarity rates between each pair of documents. Separate similarity matrices were computed for each combination of the four indexes, two similarity measure and two aliasing settings (aliased or non-aliased), resulting is 16 similarity matrices. We explain our approach to aliasing and its effect on the similarity measures in section \ref{aliasing}. Unlike the index matrices, the similarity matrices are not sparse and each entry is represented in the memory.

Similarity matrices are loaded on the startup of the application. Switching similarity measures or aliasing settings leads to redrawing of the edges of the graph according to a different matrix. Choosing a weights combination of NE's and possibly general vocabulary leads to on-the-fly computation of similarities based on the specified linear combination of values from the relevant precomputed similarity matrices.

   
\subsubsection{Keyword and Metadata Search}\label{sec:keyword_search}

Our system implements two types of possibilities for querying the database that can be combined. The first option is to query the collection by specifications on metadata. Currently this includes filtering on dates and on types of documents. These specifications are translated to MySQL queries according to which only the documents that fulfill the chosen constrains are retrieved from the database. 

The second option is to specify keywords that can be NE's or other lexical items. In order to perform queries based on keywords we transform each query to a vector representation. This is essentially the same transformation that is done for documents. Query terms and document are are normalized to lowercase and checked for exact matching. In order to determine the relevance of each document to the query the cosine similarity between the query vector and each document vector is computed. 

Note that if aliasing is enabled, an indirect query expension is performed for query terms that are NE's. If the represenration of the documents is expanded with aliases, a document might match the query because it matches one of the aliases and while not containing the exact term expressed in the query. For example, assume that a document originally contains the NE \lingform{Castro} and that the query is for the NE \lingform{Fidel Castro}. Without aliasing these two terms will not match. However, if aliasing is enabled the document might be boosted with the string \lingform{Fidel Castro} which will lead to matching between the terms. 

Combining the two types or queries is translated into a two step procedure: Firstly, documents that do not satisfy the metadata conditions of type and date of the document are filtered out. Secondly, documents are sorted in descending order according to their cosine similarity to the query. If the search is solely on metadata, documents are not sorted. Only the subset of the best results of the size specified by the user proceed to the next stage of inter-document similarity calculations.

