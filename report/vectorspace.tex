We use the Vector Space Model (VSM) as our framework for representation of documents and queries. The VSM is an established approach in IR as it enables straightforward modeling of document-query similarity in order to determine relevance of documents to the query. More crucially, it enables us to model inter-document similarity which underlies the idea of linking similar and related documents. Both similarity notions can be modeled as proximity of vectors in the multidimensional vector space. Furthermore, the VSM is a convenient representation for implementation of clustering algorithms, which provide another tool for arranging the graph nodes in an informative manner.  

The VSM is a model for representing arbitrary data as vectors in Euclidean space. In IR, this representation is used for both documents and queries. In the The value of each element of the vector corresponds to the importance of a term for the representation of the query or the document. In this basic formulation the model treats both documents and queries as "bags of words" ignoring any order or structure related information. The vectors are usually normalized in order to have the same length (e.g.\ unit length)--- Otherwise, the model would favor larger documents. 

The elegant algebraic formulation and interpretation of the VSM make this model attractive from for theoretical and practical perspectives.
Another advantage of the VSM is its flexibility as compared to more restricted models such as boolean models. In boolean models, documents that do not exactly match the query are rejected. However, in many real world scenarios, the situation is different: The relevance of the document for the user is often graded rather then binary. The VSM can model this relevance scale.


\subsubsection{Indexing}
\label{sec:indexing}
Representing the documents of our collection in vector space requires the construction of an index. Given a set of documents $\mathcal{D}$ together with a set of terms $\mathcal{T}$ the index is a matrix $D \in \mathbb{R}^{|\mathcal{D}|\times |\mathcal{T}|}$ where $D_{d,i}$ corresponds to the importance of term $i$ in document $d$. In each column, the weights for one distinct term over all the documents is stored.

Index matrices are often very sparse: In our implementation, they are represented as a sparse matrix (linked lists)--- In the data structures, only coordinates of the non-zero entries are stored, all of the document vectors being normalized in advance. This allows the compute cosine similarities for documents and queries to be computed without being normalized first.

Our model contains several index matrices. We created an index matrix for each NE type and a general index for the non-NE terms (all terms occurring in the documents). For the NE's indexes we used the output of the SNRE. For the non-NE terms (general vocabulary) we used all the vocabulary of the collection, without any filtering. Indexes are also constructed on-the-fly for queries, using the query terms.

\subsubsection{Term Weighting}
\label{sec:term_weighting}
There are several measures that can be used to express the importance of the index term for the document, perhaps the most widely used being TF and TF-IDF.

TF is the frequency of a term in a given document. Hence, TF scores grow linearly with the number of occurrences of a term in the document. The TF score of term $i$ in document $d$ is defined as:
\[\text{TF}_d(i) = \frac{n_d(i)}{\sum_{i' \in \mathcal{T}}{n_d(i')}}\]
where $n_d(i)$ denotes the number of occurrences of term $i$ in document $d$ and $\mathcal{T}$ denotes the set of all terms. 

TF-IDF is the product of term frequency and the logarithm of inverse document frequency. This measure is based on the observation that terms which occur more commonly in documents overall are less useful than terms which occur less commonly in documents overall. The TF-IDF score of term $i$ in document $d$ is is defined as
\[\text{TF-IDF}_d(i)= \text{TF}_d(i)\log{\left(\frac{|D|}{|\lbrace d' : t(i) \in d' \rbrace|}\right)}\]
The TF-IDF score of term $i$ is proportional to the logarithm of the inverse fraction of documents that contain term $i$; The smaller the logarithm, the lower the TF-IDF score. Thus, the TF-IDF score of terms which are contained in every document always equals $0$.

The difference between these two weighting schemes can have a considerable impact on the ranking of the query results as well as on the similarity measurements between the documents. Using only TF may result in an unjustified high similarity between a pair of documents due to appearances of non-discriminative terms that are frequent in every document. For instance, two completely unrelated documents can have relatively high similarity measure simply since they share NE's such as \lingform{Fidel Castro} and \lingform{Cuba} or non-NE's such functional words. TF-IDF accounts for this problem by assigning low weights for non-discriminative terms. A similar problem can happen with query-document similarity. With respect to this issue, it seems that TF/IDF is a more suitable vector representation for our similarity measurements. However, since it is possible to think of scenarios where the TF could be useful, we enable the user to switch between the two, setting TF/IDF as default. 

\subsubsection{Computing Similarity between Documents}\label{sec:computing_similarity_between_documents}

For the goal of our project, it is necessary to measure the similarity between the documents. According to similarities of the documents, edges of the resulting graph are constructed. The crucial and not easy to be answered question is, how does the similar documents look like. Our project aims at making navigation throw the collection of historical document. Historicians usually aim at some specific historical event or historical person. It follows that it is convenient to suppose that two documents, that touches the same or similar historical topic, are similar. The historical event can be usually specified by the persons, locations and organizations involved in it. Our working hypothese is that the similarity between documents, we are interrested in, can be expressed as the similarity on the named entities. As we represent documents in VSM as the vectors of named entities, we can directly apply standard vector space measures for expressing similarities between vectors. 

The most common measure is the cosine similarity measure.
\[\text{cosim}(d,d') = \sum_{k \in \mathcal{T}}\frac{d(k)d'(k)}{|d||d'|}\]
It expresses the cosine angle between the vectors $d$ and $d'$. The cosine measure is equal to $1$ for the parallel vectors and is equal to $0$ for perpendicular vectors.

We also used another similarity measure which we denoted as "Manhattan similarity measure". The reason is that the Manhattan similarity measure between two vectors can be described using the manhattan distance between zero vector and the vector whose value for each column is equal to the minimum value of those vectors for that column.

\[\text{manhattan}(d,d') = \sum_{k \in \mathcal{T}}min[d(k), d'(k)]\]


\note{Michal: I added some stuff here. You are welcomed to fix it and complete it. ADD SOMETHING HERE!!!}

The retrieved documents were arranged according to their similarity to each other. To this end, the similarity of each pair of documents was stored in similarity matrices. The matrices correspond to the four different indices: similarity according to \meta{Persons}, \meta{Locations} and \meta{Organizations} and to general vocabulary. These matrices are not sparse (unlike the index matrices) and each entry is represented in the memory.   

\subsubsection{Keyword and Metadata Search}\label{sec:keyword_search}

Searching in VSMs is implemented by transforming a search query into its vector representation in the same fashion as a document is. The cosine similarity between the query vector and the vector representation of each document is computed. The search results are then ordered according to their similarity to the user query and are returned as output. 

Document retrieval using this model consists of two steps: Firstly, documents that do not satisfy the conditions concerning the type and date of the document are filtered out. Secondly, documents are sorted in descending order according to their cosine similarity to the query. However, if the search is solely on metadata, documents are not sorted. Only the subset of the best results of the size specified by the user proceeds to the next stage.

\note{ADD CONCLUSION: WHY is this useful? WHAT do we use this for? HOW does it help in the project? e.g.\ ``By precomputing a database of bla bla ba... aliasing can be performed in real time and I can get a good grade for this fucking course''}
